{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81dd574d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import library as lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e48c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_raw = r\"C:\\phantichdulieu\\GSE282701\\GSE282701_RAW\"\n",
    "input_path = lib.os.path.join(lib.os.getcwd(), input_path_raw.split('\\\\')[-2] + '_output','adata_processed.h5ad')\n",
    "adata_in_path = lib.os.path.join(lib.os.getcwd(), input_path_raw.split('\\\\')[-2] + '_output','adata_in.h5ad')\n",
    "adata_out_path = lib.os.path.join(lib.os.getcwd(), input_path_raw.split('\\\\')[-2] + '_output','adata_out.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a7d78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_raw = lib.sc.read_h5ad(input_path)\n",
    "adata_in = lib.sc.read_h5ad(adata_in_path)\n",
    "adata_out = lib.sc.read_h5ad(adata_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61af690f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 615. MiB for an array with shape (5000, 32246) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m a0 = adata_raw.layers[\u001b[33m'\u001b[39m\u001b[33mcounts\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m a1 = \u001b[43madata_in\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcounts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m a2 = adata_out.layers[\u001b[33m'\u001b[39m\u001b[33mcounts\u001b[39m\u001b[33m'\u001b[39m].toarray()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\scipy\\sparse\\_compressed.py:996\u001b[39m, in \u001b[36m_cs_matrix.toarray\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    995\u001b[39m     order = \u001b[38;5;28mself\u001b[39m._swap(\u001b[33m'\u001b[39m\u001b[33mcf\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out.flags.c_contiguous \u001b[38;5;129;01mor\u001b[39;00m out.flags.f_contiguous):\n\u001b[32m    998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mOutput array must be C or F contiguous\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\scipy\\sparse\\_base.py:1530\u001b[39m, in \u001b[36m_spbase._process_toarray_args\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m   1528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 615. MiB for an array with shape (5000, 32246) and data type float32"
     ]
    }
   ],
   "source": [
    "a0 = adata_raw.layers['counts']\n",
    "a1 = adata_in.layers['counts'].toarray()\n",
    "a2 = adata_out.layers['counts'].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46174184",
   "metadata": {},
   "source": [
    "# inferCNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bc26589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "from collections.abc import Sequence\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.ndimage\n",
    "import scipy.sparse\n",
    "from anndata import AnnData\n",
    "from scanpy import logging\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "from infercnvpy._util import _ensure_array\n",
    "\n",
    "\n",
    "def infercnv(\n",
    "    adata: AnnData,\n",
    "    *,\n",
    "    reference_key: str | None = None,\n",
    "    reference_cat: None | str | Sequence[str] = None,\n",
    "    reference: np.ndarray | None = None,\n",
    "    lfc_clip: float = 3,\n",
    "    window_size: int = 100,\n",
    "    step: int = 10,\n",
    "    dynamic_threshold: float | None = 1.5,\n",
    "    exclude_chromosomes: Sequence[str] | None = (\"chrX\", \"chrY\"),\n",
    "    chunksize: int = 5000,\n",
    "    n_jobs: int | None = None,\n",
    "    inplace: bool = True,\n",
    "    layer: str | None = None,\n",
    "    key_added: str = \"cnv\",\n",
    "    calculate_gene_values: bool = False,\n",
    ") -> None | tuple[dict, scipy.sparse.csr_matrix, np.ndarray | None]:\n",
    "    \"\"\"Infer Copy Number Variation (CNV) by averaging gene expression over genomic regions.\n",
    "\n",
    "    This method is heavily inspired by `infercnv <https://github.com/broadinstitute/inferCNV/>`_\n",
    "    but more computationally efficient. The method is described in more detail\n",
    "    in on the :ref:`infercnv-method` page.\n",
    "\n",
    "    There, you can also find instructions on how to :ref:`prepare input data <input-data>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        annotated data matrix\n",
    "    reference_key\n",
    "        Column name in adata.obs that contains tumor/normal annotations.\n",
    "        If this is set to None, the average of all cells is used as reference.\n",
    "    reference_cat\n",
    "        One or multiple values in `adata.obs[reference_key]` that annotate\n",
    "        normal cells.\n",
    "    reference\n",
    "        Directly supply an array of average normal gene expression. Overrides\n",
    "        `reference_key` and `reference_cat`.\n",
    "    lfc_clip\n",
    "        Clip log fold changes at this value\n",
    "    window_size\n",
    "        size of the running window (number of genes in to include in the window)\n",
    "    step\n",
    "        only compute every nth running window where n = `step`. Set to 1 to compute\n",
    "        all windows.\n",
    "    dynamic_threshold\n",
    "        Values `< dynamic threshold * STDDEV` will be set to 0, where STDDEV is\n",
    "        the stadard deviation of the smoothed gene expression. Set to `None` to disable\n",
    "        this step.\n",
    "    exclude_chromosomes\n",
    "        List of chromosomes to exclude. The default is to exclude genosomes.\n",
    "    chunksize\n",
    "        Process dataset in chunks of cells. This allows to run infercnv on\n",
    "        datasets with many cells, where the dense matrix would not fit into memory.\n",
    "    n_jobs\n",
    "        Number of jobs for parallel processing. Default: use all cores.\n",
    "        Data will be submitted to workers in chunks, see `chunksize`.\n",
    "    inplace\n",
    "        If True, save the results in adata.obsm, otherwise return the CNV matrix.\n",
    "    layer\n",
    "        Layer from adata to use. If `None`, use `X`.\n",
    "    key_added\n",
    "        Key under which the cnv matrix will be stored in adata if `inplace=True`.\n",
    "        Will store the matrix in `adata.obsm[\"X_{key_added}\"] and additional information\n",
    "        in `adata.uns[key_added]`.\n",
    "    calculate_gene_values\n",
    "        If True per gene CNVs will be calculated and stored in `adata.layers[\"gene_values_{key_added}\"]`.\n",
    "        As many genes will be included in each segment the resultant per gene value will be an average of the genes included in the segment.\n",
    "        Additionally not all genes will be included in the per gene CNV, due to the window size and step size not always being a multiple of\n",
    "        the number of genes. Any genes not included in the per gene CNV will be filled with NaN.\n",
    "        Note this will significantly increase the memory and computation time, it is recommended to decrease the chunksize to ~100 if this is set to True.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Depending on inplace, either return the smoothed and denoised gene expression\n",
    "    matrix sorted by genomic position, or add it to adata.\n",
    "    \"\"\"\n",
    "    if not adata.var_names.is_unique:\n",
    "        raise ValueError(\"Ensure your var_names are unique!\")\n",
    "    if {\"chromosome\", \"start\", \"end\"} - set(adata.var.columns) != set():\n",
    "        raise ValueError(\n",
    "            \"Genomic positions not found. There need to be `chromosome`, `start`, and `end` columns in `adata.var`. \"\n",
    "        )\n",
    "\n",
    "    var_mask = adata.var[\"chromosome\"].isnull()\n",
    "    if np.sum(var_mask):\n",
    "        logging.warning(f\"Skipped {np.sum(var_mask)} genes because they don't have a genomic position annotated. \")  # type: ignore\n",
    "    if exclude_chromosomes is not None:\n",
    "        var_mask = var_mask | adata.var[\"chromosome\"].isin(exclude_chromosomes)\n",
    "\n",
    "    tmp_adata = adata[:, ~var_mask]\n",
    "    reference = _get_reference(adata, reference_key, reference_cat, reference, layer)[:, ~var_mask]\n",
    "\n",
    "    expr = tmp_adata.X if layer is None else tmp_adata.layers[layer]\n",
    "\n",
    "    if scipy.sparse.issparse(expr):\n",
    "        expr = expr.tocsr()\n",
    "\n",
    "    var = tmp_adata.var.loc[:, [\"chromosome\", \"start\", \"end\"]]  # type: ignore\n",
    "\n",
    "    chr_pos, chunks, convolved_dfs = zip(\n",
    "        *process_map(\n",
    "            _infercnv_chunk,\n",
    "            [expr[i : i + chunksize, :] for i in range(0, adata.shape[0], chunksize)],\n",
    "            itertools.repeat(var),\n",
    "            itertools.repeat(reference),\n",
    "            itertools.repeat(lfc_clip),\n",
    "            itertools.repeat(window_size),\n",
    "            itertools.repeat(step),\n",
    "            itertools.repeat(dynamic_threshold),\n",
    "            itertools.repeat(calculate_gene_values),\n",
    "            tqdm_class=tqdm,\n",
    "            max_workers=cpu_count() if n_jobs is None else n_jobs,\n",
    "        ),\n",
    "        strict=False,\n",
    "    )\n",
    "\n",
    "    res = scipy.sparse.vstack(chunks)\n",
    "\n",
    "    chr_pos = chr_pos[0]\n",
    "\n",
    "    if calculate_gene_values:\n",
    "        per_gene_df = pd.concat(convolved_dfs, axis=0)\n",
    "        # Ensure the DataFrame has the correct row index\n",
    "        per_gene_df.index = adata.obs.index\n",
    "        # Ensure the per gene CNV matches the adata var (genes) index, any genes\n",
    "        # that are not included in the CNV will be filled with NaN\n",
    "        per_gene_df = per_gene_df.reindex(columns=adata.var_names, fill_value=np.nan)\n",
    "        # This needs to be a numpy array as colnames are too large to save in anndata\n",
    "        per_gene_mtx = per_gene_df.values\n",
    "    else:\n",
    "        per_gene_mtx = None\n",
    "\n",
    "    if inplace:\n",
    "        adata.obsm[f\"X_{key_added}\"] = res\n",
    "        adata.uns[key_added] = {\"chr_pos\": chr_pos}\n",
    "\n",
    "        if calculate_gene_values:\n",
    "            adata.layers[f\"gene_values_{key_added}\"] = per_gene_mtx\n",
    "\n",
    "    else:\n",
    "        return chr_pos, res, per_gene_mtx\n",
    "\n",
    "\n",
    "def _natural_sort(l: Sequence):\n",
    "    \"\"\"Natural sort without third party libraries.\n",
    "\n",
    "    Adapted from: https://stackoverflow.com/a/4836734/2340703\n",
    "    \"\"\"\n",
    "\n",
    "    def convert(text):\n",
    "        return int(text) if text.isdigit() else text.lower()\n",
    "\n",
    "    def alphanum_key(key):\n",
    "        return [convert(c) for c in re.split(\"([0-9]+)\", key)]\n",
    "\n",
    "    return sorted(l, key=alphanum_key)\n",
    "\n",
    "\n",
    "def _running_mean(\n",
    "    x: np.ndarray | scipy.sparse.spmatrix,\n",
    "    n: int = 50,\n",
    "    step: int = 10,\n",
    "    gene_list: list = None,\n",
    "    calculate_gene_values: bool = False,\n",
    ") -> tuple[np.ndarray, pd.DataFrame | None]:\n",
    "    \"\"\"\n",
    "    Compute a pyramidially weighted running mean.\n",
    "\n",
    "    Densifies the matrix. Use `step` and `chunksize` to save memory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        matrix to work on\n",
    "    n\n",
    "        Length of the running window\n",
    "    step\n",
    "        only compute running windows every `step` columns, e.g. if step is 10\n",
    "        0:99, 10:109, 20:119 etc. Saves memory.\n",
    "    gene_list\n",
    "        List of gene names to be used in the convolution\n",
    "    calculate_gene_values\n",
    "        If True per gene CNVs will be calculated and stored in `adata.layers[\"gene_values_{key_added}\"]`.\n",
    "    \"\"\"\n",
    "    if n < x.shape[1]:  # regular convolution: the filter is smaller than the #genes\n",
    "        r = np.arange(1, n + 1)\n",
    "        pyramid = np.minimum(r, r[::-1])\n",
    "        smoothed_x = np.apply_along_axis(\n",
    "            lambda row: np.convolve(row, pyramid, mode=\"valid\"),\n",
    "            axis=1,\n",
    "            arr=x,\n",
    "        ) / np.sum(pyramid)\n",
    "\n",
    "        ## get the indices of the genes used in the convolution\n",
    "        convolution_indices = get_convolution_indices(x, n)[np.arange(0, smoothed_x.shape[1], step)]\n",
    "        ## Pull out the genes used in the convolution\n",
    "        convolved_gene_names = gene_list[convolution_indices]\n",
    "        smoothed_x = smoothed_x[:, np.arange(0, smoothed_x.shape[1], step)]\n",
    "\n",
    "        if calculate_gene_values:\n",
    "            convolved_gene_values = _calculate_gene_averages(convolved_gene_names, smoothed_x)\n",
    "        else:\n",
    "            convolved_gene_values = None\n",
    "\n",
    "        return smoothed_x, convolved_gene_values\n",
    "\n",
    "    else:  # If there is less genes than the window size, set the window size to the number of genes and perform a single convolution\n",
    "        n = x.shape[1]  # set the filter size to the number of genes\n",
    "        r = np.arange(1, n + 1)\n",
    "        ## As we are only doing one convolution the values should be equal\n",
    "        pyramid = np.array([1] * n)\n",
    "        smoothed_x = np.apply_along_axis(\n",
    "            lambda row: np.convolve(row, pyramid, mode=\"valid\"),\n",
    "            axis=1,\n",
    "            arr=x,\n",
    "        ) / np.sum(pyramid)\n",
    "\n",
    "        if calculate_gene_values:\n",
    "            ## As all genes are used the convolution the values are identical for all genes\n",
    "            convolved_gene_values = pd.DataFrame(np.repeat(smoothed_x, len(gene_list), axis=1), columns=gene_list)\n",
    "        else:\n",
    "            convolved_gene_values = None\n",
    "\n",
    "        return smoothed_x, convolved_gene_values\n",
    "\n",
    "\n",
    "def _calculate_gene_averages(\n",
    "    convolved_gene_names: np.ndarray,\n",
    "    smoothed_x: np.ndarray,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the average value of each gene in the convolution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    convolved_gene_names\n",
    "        A numpy array with the gene names used in the convolution\n",
    "    smoothed_x\n",
    "        A numpy array with the smoothed gene expression values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    convolved_gene_values\n",
    "        A DataFrame with the average value of each gene in the convolution\n",
    "    \"\"\"\n",
    "    ## create a dictionary to store the gene values per sample\n",
    "    gene_to_values = {}\n",
    "    # Calculate the number of genes in each convolution, will be same as the window size default=100\n",
    "    length = len(convolved_gene_names[0])\n",
    "    # Convert the flattened convolved gene names to a list\n",
    "    flatten_list = list(convolved_gene_names.flatten())\n",
    "\n",
    "    # For each sample in smoothed_x find the value for each gene and store it in a dictionary\n",
    "    for sample, row in enumerate(smoothed_x):\n",
    "        # Create sample level in the dictionary\n",
    "        if sample not in gene_to_values:\n",
    "            gene_to_values[sample] = {}\n",
    "        # For each gene in the flattened gene list find the value and store it in the dictionary\n",
    "        for i, gene in enumerate(flatten_list):\n",
    "            if gene not in gene_to_values[sample]:\n",
    "                gene_to_values[sample][gene] = []\n",
    "            # As the gene list has been flattend we can use the floor division of the index\n",
    "            # to get the correct position of the gene to get the value and store it in the dictionary\n",
    "            gene_to_values[sample][gene].append(row[i // length])\n",
    "\n",
    "    for sample in gene_to_values:\n",
    "        for gene in gene_to_values[sample]:\n",
    "            gene_to_values[sample][gene] = np.mean(gene_to_values[sample][gene])\n",
    "\n",
    "    convolved_gene_values = pd.DataFrame(gene_to_values).T\n",
    "    return convolved_gene_values\n",
    "\n",
    "\n",
    "def get_convolution_indices(x, n):\n",
    "    indices = []\n",
    "    for i in range(x.shape[1] - n + 1):\n",
    "        indices.append(np.arange(i, i + n))\n",
    "    return np.array(indices)\n",
    "\n",
    "\n",
    "def _running_mean_by_chromosome(\n",
    "    expr, var, window_size, step, calculate_gene_values\n",
    ") -> tuple[dict, np.ndarray, pd.DataFrame | None]:\n",
    "    \"\"\"Compute the running mean for each chromosome independently. Stack the resulting arrays ordered by chromosome.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expr\n",
    "        A gene expression matrix, appropriately preprocessed\n",
    "    var\n",
    "        The var data frame of the associated AnnData object\n",
    "    window_size\n",
    "        size of the running window (number of genes in to include in the window)\n",
    "    step\n",
    "        only compute every nth running window where n = `step`. Set to 1 to compute\n",
    "        all windows.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chr_start_pos\n",
    "        A Dictionary mapping each chromosome to the index of running_mean where\n",
    "        this chromosome begins.\n",
    "    running_mean\n",
    "        A numpy array with the smoothed gene expression, ordered by chromosome\n",
    "        and genomic position\n",
    "    \"\"\"\n",
    "    chromosomes = _natural_sort([x for x in var[\"chromosome\"].unique() if x.startswith(\"chr\") and x != \"chrM\"])\n",
    "\n",
    "    running_means = [\n",
    "        _running_mean_for_chromosome(chr, expr, var, window_size, step, calculate_gene_values) for chr in chromosomes\n",
    "    ]\n",
    "\n",
    "    running_means, convolved_dfs = zip(*running_means, strict=False)\n",
    "\n",
    "    chr_start_pos = {}\n",
    "    for chr, i in zip(chromosomes, np.cumsum([0] + [x.shape[1] for x in running_means]), strict=False):\n",
    "        chr_start_pos[chr] = i\n",
    "\n",
    "    ## Concatenate the gene dfs\n",
    "    if calculate_gene_values:\n",
    "        convolved_dfs = pd.concat(convolved_dfs, axis=1)\n",
    "\n",
    "    return chr_start_pos, np.hstack(running_means), convolved_dfs\n",
    "\n",
    "\n",
    "def _running_mean_for_chromosome(chr, expr, var, window_size, step, calculate_gene_values):\n",
    "    genes = var.loc[var[\"chromosome\"] == chr].sort_values(\"start\").index.values\n",
    "    tmp_x = expr[:, var.index.get_indexer(genes)]\n",
    "    x_conv, convolved_gene_values = _running_mean(\n",
    "        tmp_x, n=window_size, step=step, gene_list=genes, calculate_gene_values=calculate_gene_values\n",
    "    )\n",
    "\n",
    "    return x_conv, convolved_gene_values\n",
    "\n",
    "\n",
    "def _get_reference(\n",
    "    adata: AnnData,\n",
    "    reference_key: str | None,\n",
    "    reference_cat: None | str | Sequence[str],\n",
    "    reference: np.ndarray | None,\n",
    "    layer: str | None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Parameter validation extraction of reference gene expression.\n",
    "\n",
    "    If multiple reference categories are given, compute the mean per\n",
    "    category.\n",
    "\n",
    "    Returns a 2D array with reference categories in rows, cells in columns.\n",
    "    If there's just one category, it's still a 2D array.\n",
    "    \"\"\"\n",
    "    if layer is not None:\n",
    "        X = adata.layers[layer]\n",
    "    else:\n",
    "        X = adata.X\n",
    "\n",
    "    if reference is None:\n",
    "        if reference_key is None or reference_cat is None:\n",
    "            logging.warning(\n",
    "                \"Using mean of all cells as reference. For better results, \"\n",
    "                \"provide either `reference`, or both `reference_key` and `reference_cat`. \"\n",
    "            )  # type: ignore\n",
    "            reference = np.mean(X, axis=0)\n",
    "\n",
    "        else:\n",
    "            obs_col = adata.obs[reference_key]\n",
    "            if isinstance(reference_cat, str):\n",
    "                reference_cat = [reference_cat]\n",
    "            reference_cat = np.array(reference_cat)\n",
    "            reference_cat_in_obs = np.isin(reference_cat, obs_col)\n",
    "            if not np.all(reference_cat_in_obs):\n",
    "                raise ValueError(\n",
    "                    \"The following reference categories were not found in \"\n",
    "                    \"adata.obs[reference_key]: \"\n",
    "                    f\"{reference_cat[~reference_cat_in_obs]}\"\n",
    "                )\n",
    "\n",
    "            reference = np.vstack([np.mean(X[obs_col.values == cat, :], axis=0) for cat in reference_cat])\n",
    "\n",
    "    if reference.ndim == 1:\n",
    "        reference = reference[np.newaxis, :]\n",
    "\n",
    "    if reference.shape[1] != adata.shape[1]:\n",
    "        raise ValueError(\"Reference must match the number of genes in AnnData. \")\n",
    "\n",
    "    return reference\n",
    "\n",
    "\n",
    "def _infercnv_chunk(tmp_x, var, reference, lfc_cap, window_size, step, dynamic_threshold, calculate_gene_values=False):\n",
    "    \"\"\"The actual infercnv work is happening here.\n",
    "\n",
    "    Process chunks of serveral thousand genes independently since this\n",
    "    leads to (temporary) densification of the matrix.\n",
    "\n",
    "    Parameters see `infercnv`.\n",
    "    \"\"\"\n",
    "    # Step 1 - compute log fold change. This densifies the matrix.\n",
    "    # Per default, use \"bounded\" difference calculation, if multiple references\n",
    "    # are available. This mitigates cell-type specific biases (HLA, IGHG, ...)\n",
    "    if reference.shape[0] == 1:\n",
    "        x_centered = tmp_x - reference[0, :]\n",
    "    else:\n",
    "        ref_min = np.min(reference, axis=0)\n",
    "        ref_max = np.max(reference, axis=0)\n",
    "        # entries that are between the two \"bounds\" are considered having a logFC of 0.\n",
    "        x_centered = np.zeros(tmp_x.shape, dtype=tmp_x.dtype)\n",
    "        above_max = tmp_x > ref_max\n",
    "        below_min = tmp_x < ref_min\n",
    "        x_centered[above_max] = _ensure_array(tmp_x - ref_max)[above_max]\n",
    "        x_centered[below_min] = _ensure_array(tmp_x - ref_min)[below_min]\n",
    "\n",
    "    x_centered = _ensure_array(x_centered)\n",
    "    # Step 2 - clip log fold changes\n",
    "    x_clipped = np.clip(x_centered, -lfc_cap, lfc_cap)\n",
    "    # Step 3 - smooth by genomic position\n",
    "    chr_pos, x_smoothed, conv_df = _running_mean_by_chromosome(\n",
    "        x_clipped, var, window_size=window_size, step=step, calculate_gene_values=calculate_gene_values\n",
    "    )\n",
    "    # Step 4 - center by cell\n",
    "    x_res = x_smoothed - np.median(x_smoothed, axis=1)[:, np.newaxis]\n",
    "    if calculate_gene_values:\n",
    "        gene_res = conv_df - np.median(conv_df, axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        gene_res = None\n",
    "\n",
    "    # step 5 - standard deviation based noise filtering\n",
    "    if dynamic_threshold is not None:\n",
    "        noise_thres = dynamic_threshold * np.std(x_res)\n",
    "        x_res[np.abs(x_res) < noise_thres] = 0\n",
    "        if calculate_gene_values:\n",
    "            gene_res[np.abs(gene_res) < noise_thres] = 0\n",
    "\n",
    "    x_res = scipy.sparse.csr_matrix(x_res)\n",
    "\n",
    "    return chr_pos, x_res, gene_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967337e",
   "metadata": {},
   "source": [
    "# Test inferCNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b445540",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "836a8f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 124455 × 32246\n",
       "    obs: 'sample', 'group', 'batch', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'n_genes', 'leiden', 'cell_type'\n",
       "    var: 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'chromosome', 'start', 'end'\n",
       "    uns: 'cell_type_colors', 'dendrogram_leiden', 'hvg', 'leiden', 'log1p', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03602eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mask = adata.var[\"chromosome\"].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19f59df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_adata = adata[:, ~var_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd8e5c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 124455 × 32246\n",
       "    obs: 'sample', 'group', 'batch', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'n_genes', 'leiden', 'cell_type'\n",
       "    var: 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'chromosome', 'start', 'end'\n",
       "    uns: 'cell_type_colors', 'dendrogram_leiden', 'hvg', 'leiden', 'log1p', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51d8c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_key=\"cell_type\"\n",
    "reference_cat=[\n",
    "\"T/NK\"\n",
    "]\n",
    "reference: np.ndarray | None = None\n",
    "lfc_clip: float = 3\n",
    "window_size: int = 100\n",
    "step: int = 10\n",
    "dynamic_threshold: float | None = 1.5\n",
    "exclude_chromosomes: Sequence[str] | None = (\"chrX\", \"chrY\")\n",
    "chunksize: int = 5000\n",
    "n_jobs: int | None = None\n",
    "inplace: bool = True\n",
    "layer: str | None = 'counts'\n",
    "key_added: str = \"cnv\"\n",
    "calculate_gene_values: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c91e46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.2870734e-05, 2.8130990e-03, 2.2870734e-05, ..., 2.2870734e-05,\n",
       "         8.8738669e-03, 0.0000000e+00]], shape=(1, 32246), dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = _get_reference(adata, reference_key, reference_cat, reference, layer)[:, ~var_mask]\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6ef0415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 240333629 stored elements and shape (124455, 32246)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = tmp_adata.X if layer is None else tmp_adata.layers[layer]\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed85188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scipy.sparse.issparse(expr):\n",
    "    expr = expr.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ba06f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chromosome</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIR1302-2HG</th>\n",
       "      <td>chr1</td>\n",
       "      <td>29554</td>\n",
       "      <td>31109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>89295</td>\n",
       "      <td>133723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>139790</td>\n",
       "      <td>140339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.5</th>\n",
       "      <td>chr1</td>\n",
       "      <td>141474</td>\n",
       "      <td>173862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP006222.2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>266855</td>\n",
       "      <td>268655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC136352.3</th>\n",
       "      <td>KI270727.1</td>\n",
       "      <td>100123</td>\n",
       "      <td>101141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC136616.3</th>\n",
       "      <td>KI270728.1</td>\n",
       "      <td>1157687</td>\n",
       "      <td>1240349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC136616.2</th>\n",
       "      <td>KI270728.1</td>\n",
       "      <td>1167457</td>\n",
       "      <td>1257196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC007325.4</th>\n",
       "      <td>KI270734.1</td>\n",
       "      <td>131494</td>\n",
       "      <td>137392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC007325.2</th>\n",
       "      <td>KI270734.1</td>\n",
       "      <td>138082</td>\n",
       "      <td>161852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32246 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             chromosome    start      end\n",
       "MIR1302-2HG        chr1    29554    31109\n",
       "AL627309.1         chr1    89295   133723\n",
       "AL627309.2         chr1   139790   140339\n",
       "AL627309.5         chr1   141474   173862\n",
       "AP006222.2         chr1   266855   268655\n",
       "...                 ...      ...      ...\n",
       "AC136352.3   KI270727.1   100123   101141\n",
       "AC136616.3   KI270728.1  1157687  1240349\n",
       "AC136616.2   KI270728.1  1167457  1257196\n",
       "AC007325.4   KI270734.1   131494   137392\n",
       "AC007325.2   KI270734.1   138082   161852\n",
       "\n",
       "[32246 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = tmp_adata.var.loc[:, [\"chromosome\", \"start\", \"end\"]]  # type: ignore\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0515798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infercnv_chunk(tmp_x, var, reference, lfc_cap, window_size, step, dynamic_threshold, calculate_gene_values=False):\n",
    "    \"\"\"The actual infercnv work is happening here.\n",
    "\n",
    "    Process chunks of serveral thousand genes independently since this\n",
    "    leads to (temporary) densification of the matrix.\n",
    "\n",
    "    Parameters see `infercnv`.\n",
    "    \"\"\"\n",
    "    # Step 1 - compute log fold change. This densifies the matrix.\n",
    "    # Per default, use \"bounded\" difference calculation, if multiple references\n",
    "    # are available. This mitigates cell-type specific biases (HLA, IGHG, ...)\n",
    "    if reference.shape[0] == 1:\n",
    "        x_centered = tmp_x - reference[0, :]\n",
    "    else:\n",
    "        ref_min = np.min(reference, axis=0)\n",
    "        ref_max = np.max(reference, axis=0)\n",
    "        # entries that are between the two \"bounds\" are considered having a logFC of 0.\n",
    "        x_centered = np.zeros(tmp_x.shape, dtype=tmp_x.dtype)\n",
    "        above_max = tmp_x > ref_max\n",
    "        below_min = tmp_x < ref_min\n",
    "        x_centered[above_max] = _ensure_array(tmp_x - ref_max)[above_max]\n",
    "        x_centered[below_min] = _ensure_array(tmp_x - ref_min)[below_min]\n",
    "\n",
    "    x_centered = _ensure_array(x_centered)\n",
    "    # Step 2 - clip log fold changes\n",
    "    x_clipped = np.clip(x_centered, -lfc_cap, lfc_cap)\n",
    "    # Step 3 - smooth by genomic position\n",
    "    chr_pos, x_smoothed, conv_df = _running_mean_by_chromosome(\n",
    "        x_clipped, var, window_size=window_size, step=step, calculate_gene_values=calculate_gene_values\n",
    "    )\n",
    "    # Step 4 - center by cell\n",
    "    x_res = x_smoothed - np.median(x_smoothed, axis=1)[:, np.newaxis]\n",
    "    if calculate_gene_values:\n",
    "        gene_res = conv_df - np.median(conv_df, axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        gene_res = None\n",
    "\n",
    "    # step 5 - standard deviation based noise filtering\n",
    "    if dynamic_threshold is not None:\n",
    "        noise_thres = dynamic_threshold * np.std(x_res)\n",
    "        x_res[np.abs(x_res) < noise_thres] = 0\n",
    "        if calculate_gene_values:\n",
    "            gene_res[np.abs(gene_res) < noise_thres] = 0\n",
    "\n",
    "    x_res = scipy.sparse.csr_matrix(x_res)\n",
    "\n",
    "    return chr_pos, x_res, gene_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5a396f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "std::bad_alloc",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m chr_pos, chunks, convolved_dfs = \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m      2\u001b[39m         *process_map(\n\u001b[32m      3\u001b[39m             _infercnv_chunk,\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m             [\u001b[43mexpr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, adata.shape[\u001b[32m0\u001b[39m], chunksize)],\n\u001b[32m      5\u001b[39m             itertools.repeat(var),\n\u001b[32m      6\u001b[39m             itertools.repeat(reference),\n\u001b[32m      7\u001b[39m             itertools.repeat(lfc_clip),\n\u001b[32m      8\u001b[39m             itertools.repeat(window_size),\n\u001b[32m      9\u001b[39m             itertools.repeat(step),\n\u001b[32m     10\u001b[39m             itertools.repeat(dynamic_threshold),\n\u001b[32m     11\u001b[39m             itertools.repeat(calculate_gene_values),\n\u001b[32m     12\u001b[39m             tqdm_class=tqdm,\n\u001b[32m     13\u001b[39m             max_workers=cpu_count() \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m n_jobs,\n\u001b[32m     14\u001b[39m         ),\n\u001b[32m     15\u001b[39m         strict=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\scipy\\sparse\\_index.py:78\u001b[39m, in \u001b[36mIndexMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     76\u001b[39m         res = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_sliceXslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m col.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m     80\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._get_sliceXarray(row, col)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\scipy\\sparse\\_compressed.py:553\u001b[39m, in \u001b[36m_cs_matrix._get_sliceXslice\u001b[39m\u001b[34m(self, row, col)\u001b[39m\n\u001b[32m    551\u001b[39m major, minor = \u001b[38;5;28mself\u001b[39m._swap((row, col))\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m major.step \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m minor.step \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_submatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._major_slice(major)._minor_slice(minor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\scipy\\sparse\\_compressed.py:715\u001b[39m, in \u001b[36m_cs_matrix._get_submatrix\u001b[39m\u001b[34m(self, major, minor, copy)\u001b[39m\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i0 == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j0 == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i1 == M \u001b[38;5;129;01mand\u001b[39;00m j1 == N:\n\u001b[32m    713\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy() \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m indptr, indices, data = \u001b[43mget_csr_submatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m shape = \u001b[38;5;28mself\u001b[39m._swap((i1 - i0, j1 - j0))\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mMemoryError\u001b[39m: std::bad_alloc"
     ]
    }
   ],
   "source": [
    "chr_pos, chunks, convolved_dfs = zip(\n",
    "        *process_map(\n",
    "            _infercnv_chunk,\n",
    "            [expr[i : i + chunksize, :] for i in range(0, adata.shape[0], chunksize)],\n",
    "            itertools.repeat(var),\n",
    "            itertools.repeat(reference),\n",
    "            itertools.repeat(lfc_clip),\n",
    "            itertools.repeat(window_size),\n",
    "            itertools.repeat(step),\n",
    "            itertools.repeat(dynamic_threshold),\n",
    "            itertools.repeat(calculate_gene_values),\n",
    "            tqdm_class=tqdm,\n",
    "            max_workers=cpu_count() if n_jobs is None else n_jobs,\n",
    "        ),\n",
    "        strict=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad6378",
   "metadata": {},
   "source": [
    "# Check inferCNV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb315d6",
   "metadata": {},
   "source": [
    "Check inferCNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184930e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
